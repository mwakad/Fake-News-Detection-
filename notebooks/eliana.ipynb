{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e799fc00",
   "metadata": {},
   "source": [
    "# Fake News Detection\n",
    "**Name:** Eliana Kariuki\n",
    "\n",
    "**Group:** Group 2B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357fc69",
   "metadata": {},
   "source": [
    "### BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb98ba5",
   "metadata": {},
   "source": [
    "In today's information-driven society, the spread of misinformation and fake news through online news dissemination platforms and social media platforms has become a serious threat to public trust, democracy, health communication, and media integrity. The ability to automatically distinguish fake from real news is essential for:\n",
    "\n",
    "Social media platforms (e.g., Meta, Twitter/X, Reddit). \n",
    "Fact-checking organizations. \n",
    "News aggregators (e.g., Google News, Apple News). \n",
    "The general public. \n",
    "\n",
    "\n",
    "#### Problem Statement:\n",
    "\n",
    "The proliferation of fake news on digital platforms poses a significant risk to public trust and decision-making. Traditional methods of identifying fake news are slow and resource-intensive, making it difficult to manage the vast volume of online content.\n",
    "\n",
    "#### Proposed solution\n",
    "This project aims to develop an automated binary classification system using transformer-based Natural Language Processing (NLP) models to detect and flag fake news articles with high accuracy. By leveraging advanced NLP techniques, the system will offer a scalable solution to help identify harmful misinformation, improving information credibility and supporting the fight against digital manipulation.\n",
    "\n",
    "#### OBJECTIVES\n",
    "1. Improve Detection Accuracy with Advanced Models:\n",
    "\n",
    "Leverage state-of-the-art models (e.g., BERT, RoBERTa, XGBoost) to increase the accuracy of fake news detection, ensuring that only credible news reaches the end-users.\n",
    "\n",
    "2. Automate Fake News Detection for Real-Time Content Moderation:\n",
    "\n",
    "Implement machine learning algorithms (e.g., Logistic Regression, Naïve Bayes, Random Forest) for real-time detection and flagging of fake news across social media platforms and news websites, enhancing content moderation efficiency.\n",
    "\n",
    "3. Enhance Content Trustworthiness for News Platforms:\n",
    "\n",
    "Use transformer-based models (e.g., BERT, DistilBERT) to automatically validate the authenticity of news articles, thereby improving the trustworthiness and reliability of content presented to users on platforms like Google News and Twitter.\n",
    "\n",
    "4. Reduce the Spread of Misinformation through Scalable Solutions:\n",
    "\n",
    "Deploy scalable models such as XGBoost and LSTM to identify fake news across large volumes of content, helping reduce the widespread impact of misinformation in areas like public health and politics.\n",
    "\n",
    "5. Support Fact-Checking Organizations with Efficient Tools:\n",
    "\n",
    "Enable fact-checking organizations to use machine learning models like RoBERTa and Naïve Bayes to automate the verification of news, increasing operational efficiency and response times to counter fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3ef1f",
   "metadata": {},
   "source": [
    "### Data source\n",
    "We use 4 labelled datasets \n",
    "- gossipcop_fake.csv\n",
    "-  gossipcop_real.csv\n",
    "- politifact_fake.csv\n",
    "- politifact_real.csv\n",
    "\n",
    "The data was cloned from the FakeNewsNet Dataset (https://github.com/KaiDMML/FakeNewsNet/tree/master/dataset).  \n",
    "\n",
    "Each of the four datasets contain the following metadata:\n",
    "- id: Unique identifier for each news article\n",
    "- news_url:  The URL link for a news article\n",
    "- title: A news article’s title.\n",
    "- tweet _id: twitter profile id that shared the link to the social media platform.\n",
    "\n",
    "### Data scrapping\n",
    "For this project, we scraped from the 4 labelled datasets, specifically targeting articles labeled as fake or real. The data scraping process enabled the collection of a diverse set of news articles from prominent platforms, ensuring a comprehensive dataset for training and evaluating the fake news detection model. This dataset will then preprocessed and prepared for analysis, allowing for the development of an automated system to detect misinformation effectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcb793",
   "metadata": {},
   "source": [
    "### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed5cb0",
   "metadata": {},
   "source": [
    "In data preparation we will do the following:\n",
    "\n",
    "- Loading the data:Importing data from various sources (e.g., CSV, Excel, databases) into a working environment like Pandas DataFrame.\n",
    "\n",
    "- Exploratory Data Analysis: Inspecting the data to understand its structure, types, and initial statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeded86",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d289b",
   "metadata": {},
   "source": [
    "### Data Preprocessing for Fake News Detection: Summary\n",
    "\n",
    "To prepare the dataset for fake news detection, the following preprocessing steps will be undertaken:\n",
    "\n",
    "1. **Handling Missing Data**:\n",
    "\n",
    "   * Check for and handle any missing values (though none are expected based on the current dataset).\n",
    "\n",
    "2. **Text Preprocessing**:\n",
    "\n",
    "   * **Lowercasing**: Convert all text in both `title` and `extracted_article_text` to lowercase for consistency.\n",
    "   * **Removing Punctuation & Special Characters**: Clean the text by removing punctuation, special characters, and non-alphanumeric symbols.\n",
    "   * **Removing Stop Words**: Remove common, non-informative words (e.g., “the,” “and,” “of”) from the text.\n",
    "   * **Tokenization**: Split the text into individual words (tokens).\n",
    "   * **Stemming/Lemmatization**: Reduce words to their root form (e.g., \"running\" → \"run\").\n",
    "   * **Removing URLs & Numbers**: Eliminate URLs and numerical data, as they are usually not relevant for classification.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "\n",
    "   * **Text Length Features**: Calculate text length, word count, sentence count, and character count to capture relevant patterns.\n",
    "\n",
    "4. **Text Vectorization**:\n",
    "\n",
    "   * **Bag of Words (BoW)**: Convert text into a matrix of word frequencies.\n",
    "   * **TF-IDF (Term Frequency-Inverse Document Frequency)**: Transform text into numerical vectors, considering the importance of words in the context of the entire dataset.\n",
    "   * **Word Embeddings (Optional)**: Use Word2Vec or GloVe if semantic representation of words is required.\n",
    "\n",
    "5. **Label Encoding**:\n",
    "\n",
    "   * The target variable (`class`) is already encoded (0 for real news, 1 for fake news), so no further encoding is necessary.\n",
    "\n",
    "6. **Train-Test Split**:\n",
    "\n",
    "   * Split the dataset into training and testing sets (typically 80-20 or 70-30) to allow for model evaluation on unseen data.\n",
    "\n",
    "7. **Scaling Features (Optional)**:\n",
    "\n",
    "   * For certain machine learning algorithms (e.g., SVM, KNN), scaling numerical features like word count or sentence count may be required.\n",
    "\n",
    "8. **Handling Class Imbalance (Optional)**:\n",
    "\n",
    "   * If the dataset shows an imbalance between real and fake news articles, techniques like oversampling, undersampling, or using algorithms designed for imbalanced datasets may be applied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
